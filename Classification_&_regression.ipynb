{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1970e1d9",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\priyanshu chauhan\\anaconda3\\lib\\site-packages (2.14.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.14.0 in c:\\users\\priyanshu chauhan\\anaconda3\\lib\\site-packages (from tensorflow) (2.14.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\priyanshu chauhan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\priyanshu chauhan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\priyanshu chauhan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\priyanshu chauhan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\priyanshu chauhan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\priyanshu chauhan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\priyanshu chauhan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes==0.2.0 in c:\\users\\priyanshu chauhan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy>=1.23.5 in c:\\users\\priyanshu chauhan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\priyanshu chauhan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\priyanshu chauhan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (23.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\priyanshu chauhan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (4.24.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\priyanshu chauhan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (67.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\priyanshu chauhan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\priyanshu chauhan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\priyanshu chauhan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (4.6.3)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\priyanshu chauhan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\priyanshu chauhan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\priyanshu chauhan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.59.0)\n",
      "Requirement already satisfied: tensorboard<2.15,>=2.14 in c:\\users\\priyanshu chauhan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.14.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in c:\\users\\priyanshu chauhan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.14.0)\n",
      "Requirement already satisfied: keras<2.15,>=2.14.0 in c:\\users\\priyanshu chauhan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.14.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\priyanshu chauhan\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.14.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\priyanshu chauhan\\anaconda3\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.23.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\priyanshu chauhan\\anaconda3\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\priyanshu chauhan\\anaconda3\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\priyanshu chauhan\\anaconda3\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.29.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\priyanshu chauhan\\anaconda3\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\priyanshu chauhan\\anaconda3\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\priyanshu chauhan\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\priyanshu chauhan\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\priyanshu chauhan\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\priyanshu chauhan\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\priyanshu chauhan\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\priyanshu chauhan\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\priyanshu chauhan\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\priyanshu chauhan\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2023.5.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\priyanshu chauhan\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\priyanshu chauhan\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\priyanshu chauhan\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71b74c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import Sequential\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aceb4f84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9996</td>\n",
       "      <td>15606229</td>\n",
       "      <td>Obijiaku</td>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9997</td>\n",
       "      <td>15569892</td>\n",
       "      <td>Johnstone</td>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9998</td>\n",
       "      <td>15584532</td>\n",
       "      <td>Liu</td>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9999</td>\n",
       "      <td>15682355</td>\n",
       "      <td>Sabbatini</td>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10000</td>\n",
       "      <td>15628319</td>\n",
       "      <td>Walker</td>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  CustomerId    Surname  CreditScore Geography  Gender  Age  \\\n",
       "0             1    15634602   Hargrave          619    France  Female   42   \n",
       "1             2    15647311       Hill          608     Spain  Female   41   \n",
       "2             3    15619304       Onio          502    France  Female   42   \n",
       "3             4    15701354       Boni          699    France  Female   39   \n",
       "4             5    15737888   Mitchell          850     Spain  Female   43   \n",
       "...         ...         ...        ...          ...       ...     ...  ...   \n",
       "9995       9996    15606229   Obijiaku          771    France    Male   39   \n",
       "9996       9997    15569892  Johnstone          516    France    Male   35   \n",
       "9997       9998    15584532        Liu          709    France  Female   36   \n",
       "9998       9999    15682355  Sabbatini          772   Germany    Male   42   \n",
       "9999      10000    15628319     Walker          792    France  Female   28   \n",
       "\n",
       "      Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0          2       0.00              1          1               1   \n",
       "1          1   83807.86              1          0               1   \n",
       "2          8  159660.80              3          1               0   \n",
       "3          1       0.00              2          0               0   \n",
       "4          2  125510.82              1          1               1   \n",
       "...      ...        ...            ...        ...             ...   \n",
       "9995       5       0.00              2          1               0   \n",
       "9996      10   57369.61              1          1               1   \n",
       "9997       7       0.00              1          0               1   \n",
       "9998       3   75075.31              2          1               0   \n",
       "9999       4  130142.79              1          1               0   \n",
       "\n",
       "      EstimatedSalary  Exited  \n",
       "0           101348.88       1  \n",
       "1           112542.58       0  \n",
       "2           113931.57       1  \n",
       "3            93826.63       0  \n",
       "4            79084.10       0  \n",
       "...               ...     ...  \n",
       "9995         96270.64       0  \n",
       "9996        101699.77       0  \n",
       "9997         42085.58       1  \n",
       "9998         92888.52       1  \n",
       "9999         38190.78       0  \n",
       "\n",
       "[10000 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"D:\\\\Datasets-main\\\\Churn_Modelling.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46bff73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['RowNumber','CustomerId','Surname'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d71fc5e",
   "metadata": {},
   "source": [
    "# Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b93a8c33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0             619    France  Female   42       2       0.00              1   \n",
       "1             608     Spain  Female   41       1   83807.86              1   \n",
       "2             502    France  Female   42       8  159660.80              3   \n",
       "3             699    France  Female   39       1       0.00              2   \n",
       "4             850     Spain  Female   43       2  125510.82              1   \n",
       "...           ...       ...     ...  ...     ...        ...            ...   \n",
       "9995          771    France    Male   39       5       0.00              2   \n",
       "9996          516    France    Male   35      10   57369.61              1   \n",
       "9997          709    France  Female   36       7       0.00              1   \n",
       "9998          772   Germany    Male   42       3   75075.31              2   \n",
       "9999          792    France  Female   28       4  130142.79              1   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0             1               1        101348.88       1  \n",
       "1             0               1        112542.58       0  \n",
       "2             1               0        113931.57       1  \n",
       "3             0               0         93826.63       0  \n",
       "4             1               1         79084.10       0  \n",
       "...         ...             ...              ...     ...  \n",
       "9995          1               0         96270.64       0  \n",
       "9996          1               1        101699.77       0  \n",
       "9997          0               1         42085.58       1  \n",
       "9998          1               0         92888.52       1  \n",
       "9999          1               0         38190.78       0  \n",
       "\n",
       "[10000 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6daf5f52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0             619   42       2       0.00              1          1   \n",
       "1             608   41       1   83807.86              1          0   \n",
       "2             502   42       8  159660.80              3          1   \n",
       "3             699   39       1       0.00              2          0   \n",
       "4             850   43       2  125510.82              1          1   \n",
       "...           ...  ...     ...        ...            ...        ...   \n",
       "9995          771   39       5       0.00              2          1   \n",
       "9996          516   35      10   57369.61              1          1   \n",
       "9997          709   36       7       0.00              1          0   \n",
       "9998          772   42       3   75075.31              2          1   \n",
       "9999          792   28       4  130142.79              1          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Exited  Geography_France  \\\n",
       "0                  1        101348.88       1                 1   \n",
       "1                  1        112542.58       0                 0   \n",
       "2                  0        113931.57       1                 1   \n",
       "3                  0         93826.63       0                 1   \n",
       "4                  1         79084.10       0                 0   \n",
       "...              ...              ...     ...               ...   \n",
       "9995               0         96270.64       0                 1   \n",
       "9996               1        101699.77       0                 1   \n",
       "9997               1         42085.58       1                 1   \n",
       "9998               0         92888.52       1                 0   \n",
       "9999               0         38190.78       0                 1   \n",
       "\n",
       "      Geography_Germany  Geography_Spain  Gender_Female  Gender_Male  \n",
       "0                     0                0              1            0  \n",
       "1                     0                1              1            0  \n",
       "2                     0                0              1            0  \n",
       "3                     0                0              1            0  \n",
       "4                     0                1              1            0  \n",
       "...                 ...              ...            ...          ...  \n",
       "9995                  0                0              0            1  \n",
       "9996                  0                0              0            1  \n",
       "9997                  0                0              1            0  \n",
       "9998                  1                0              0            1  \n",
       "9999                  0                0              1            0  \n",
       "\n",
       "[10000 rows x 14 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.get_dummies(data=df, columns=['Geography','Gender'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8d2368",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4acdee94",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "x = df.drop(columns=['Exited'])\n",
    "y = df['Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c618a287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.32622142,  0.29351742, -1.04175968, ..., -0.57380915,\n",
       "         1.09598752, -1.09598752],\n",
       "       [-0.44003595,  0.19816383, -1.38753759, ...,  1.74273971,\n",
       "         1.09598752, -1.09598752],\n",
       "       [-1.53679418,  0.29351742,  1.03290776, ..., -0.57380915,\n",
       "         1.09598752, -1.09598752],\n",
       "       ...,\n",
       "       [ 0.60498839, -0.27860412,  0.68712986, ..., -0.57380915,\n",
       "         1.09598752, -1.09598752],\n",
       "       [ 1.25683526,  0.29351742, -0.69598177, ..., -0.57380915,\n",
       "        -0.91241915,  0.91241915],\n",
       "       [ 1.46377078, -1.04143285, -0.35020386, ..., -0.57380915,\n",
       "         1.09598752, -1.09598752]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = sc.fit_transform(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "849f8476",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain,xtest,ytrain,ytest = train_test_split(x,y,test_size=0.20, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e255d792",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 2s 4ms/step - loss: 0.7692 - accuracy: 0.4271\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.7681 - accuracy: 0.4285\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.7669 - accuracy: 0.4304\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.7656 - accuracy: 0.4322\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.7644 - accuracy: 0.4341\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.7630 - accuracy: 0.4360\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.7617 - accuracy: 0.4365\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.7604 - accuracy: 0.4383\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.7590 - accuracy: 0.4403\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.7577 - accuracy: 0.4416\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.7563 - accuracy: 0.4434\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.7549 - accuracy: 0.4451\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.7536 - accuracy: 0.4474\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.7522 - accuracy: 0.4494\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.7508 - accuracy: 0.4514\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.7495 - accuracy: 0.4530\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.7481 - accuracy: 0.4549\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.7467 - accuracy: 0.4561\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.7454 - accuracy: 0.4577\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.7440 - accuracy: 0.4604\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.7427 - accuracy: 0.4622\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.7413 - accuracy: 0.4642\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.7400 - accuracy: 0.4656\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.7386 - accuracy: 0.4675\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.7373 - accuracy: 0.4694\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.7359 - accuracy: 0.4717\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.7346 - accuracy: 0.4734\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.7333 - accuracy: 0.4761\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.7320 - accuracy: 0.4775\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.7307 - accuracy: 0.4803\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.7294 - accuracy: 0.4819\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.7281 - accuracy: 0.4837\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.7268 - accuracy: 0.4859\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.7255 - accuracy: 0.4874\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.7242 - accuracy: 0.4897\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.7229 - accuracy: 0.4918\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.7216 - accuracy: 0.4934\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.7204 - accuracy: 0.4964\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.7191 - accuracy: 0.4989\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.7178 - accuracy: 0.5013\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.7166 - accuracy: 0.5030\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.7153 - accuracy: 0.5045\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.7141 - accuracy: 0.5058\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.7128 - accuracy: 0.5073\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.7116 - accuracy: 0.5090\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.7104 - accuracy: 0.5110\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.7092 - accuracy: 0.5131\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.7079 - accuracy: 0.5154\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.7067 - accuracy: 0.5173\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.7055 - accuracy: 0.5200\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.7043 - accuracy: 0.5222\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.7032 - accuracy: 0.5241\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.7020 - accuracy: 0.5256\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.7008 - accuracy: 0.5279\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.6996 - accuracy: 0.5293\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.6985 - accuracy: 0.5325\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.6973 - accuracy: 0.5347\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.6961 - accuracy: 0.5370\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.6950 - accuracy: 0.5397\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.6939 - accuracy: 0.5421\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.6927 - accuracy: 0.5450\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.6916 - accuracy: 0.5459\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.6905 - accuracy: 0.5477\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.6893 - accuracy: 0.5500\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.6882 - accuracy: 0.5520\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.6871 - accuracy: 0.5541\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.6860 - accuracy: 0.5555\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.6849 - accuracy: 0.5573\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.6838 - accuracy: 0.5590\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.6827 - accuracy: 0.5612\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.6817 - accuracy: 0.5626\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.6806 - accuracy: 0.5651\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.6795 - accuracy: 0.5673\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.6784 - accuracy: 0.5691\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.6774 - accuracy: 0.5717\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.6763 - accuracy: 0.5739\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.6753 - accuracy: 0.5765\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.6742 - accuracy: 0.5799\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.6732 - accuracy: 0.5817\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.6721 - accuracy: 0.5840\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.6711 - accuracy: 0.5861\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.6701 - accuracy: 0.5879\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.6691 - accuracy: 0.5909\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.6681 - accuracy: 0.5925\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.6671 - accuracy: 0.5956\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.6661 - accuracy: 0.5984\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.6650 - accuracy: 0.5994\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.6640 - accuracy: 0.6011\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.6630 - accuracy: 0.6030\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.6621 - accuracy: 0.6037\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.6611 - accuracy: 0.6055\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.6601 - accuracy: 0.6074\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.6591 - accuracy: 0.6091\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.6581 - accuracy: 0.6112\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.6572 - accuracy: 0.6127\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.6562 - accuracy: 0.6146\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.6552 - accuracy: 0.6169\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.6543 - accuracy: 0.6183\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.6533 - accuracy: 0.6198\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.6524 - accuracy: 0.6215\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1c4a315c190>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize model\n",
    "ann = Sequential()\n",
    "\n",
    "#Add hidden layer\n",
    "ann.add(Dense(units=10,activation='relu'))\n",
    "\n",
    "#Add output layer\n",
    "ann.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "#Establish the connection between the layers\n",
    "ann.compile(optimizer = 'adadelta',loss='binary_crossentropy',metrics='accuracy')\n",
    "\n",
    "#Fit the data\n",
    "ann.fit(xtrain,ytrain, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38778b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.519839  ],\n",
       "       [0.22730082],\n",
       "       [0.49550724],\n",
       "       ...,\n",
       "       [0.4376087 ],\n",
       "       [0.5765109 ],\n",
       "       [0.34144536]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred = ann.predict(xtest)\n",
    "ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53660e75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       ...,\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc2b631c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       ...,\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred = ypred > 0.5\n",
    "ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed5fc5e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9953    0\n",
       "3850    0\n",
       "4962    0\n",
       "3886    0\n",
       "5437    0\n",
       "       ..\n",
       "3919    0\n",
       "162     0\n",
       "7903    0\n",
       "2242    0\n",
       "2745    0\n",
       "Name: Exited, Length: 2000, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0c699c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.66      0.74      1585\n",
      "           1       0.28      0.49      0.36       415\n",
      "\n",
      "    accuracy                           0.63      2000\n",
      "   macro avg       0.56      0.58      0.55      2000\n",
      "weighted avg       0.72      0.63      0.66      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ytest,ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb0bf43f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7963\n",
       "1    2037\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Exited'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2caa9a2",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86142d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras-tuner in c:\\users\\priyanshu chauhan\\anaconda3\\lib\\site-packages (1.4.5)\n",
      "Requirement already satisfied: keras-core in c:\\users\\priyanshu chauhan\\anaconda3\\lib\\site-packages (from keras-tuner) (0.1.7)\n",
      "Requirement already satisfied: packaging in c:\\users\\priyanshu chauhan\\anaconda3\\lib\\site-packages (from keras-tuner) (23.0)\n",
      "Requirement already satisfied: requests in c:\\users\\priyanshu chauhan\\anaconda3\\lib\\site-packages (from keras-tuner) (2.29.0)\n",
      "Requirement already satisfied: kt-legacy in c:\\users\\priyanshu chauhan\\anaconda3\\lib\\site-packages (from keras-tuner) (1.0.5)\n",
      "Requirement already satisfied: absl-py in c:\\users\\priyanshu chauhan\\anaconda3\\lib\\site-packages (from keras-core->keras-tuner) (2.0.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\priyanshu chauhan\\anaconda3\\lib\\site-packages (from keras-core->keras-tuner) (1.24.3)\n",
      "Requirement already satisfied: rich in c:\\users\\priyanshu chauhan\\anaconda3\\lib\\site-packages (from keras-core->keras-tuner) (13.6.0)\n",
      "Requirement already satisfied: namex in c:\\users\\priyanshu chauhan\\anaconda3\\lib\\site-packages (from keras-core->keras-tuner) (0.0.7)\n",
      "Requirement already satisfied: h5py in c:\\users\\priyanshu chauhan\\anaconda3\\lib\\site-packages (from keras-core->keras-tuner) (3.7.0)\n",
      "Requirement already satisfied: dm-tree in c:\\users\\priyanshu chauhan\\anaconda3\\lib\\site-packages (from keras-core->keras-tuner) (0.1.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\priyanshu chauhan\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\priyanshu chauhan\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\priyanshu chauhan\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\priyanshu chauhan\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (2023.5.7)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\priyanshu chauhan\\anaconda3\\lib\\site-packages (from rich->keras-core->keras-tuner) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\priyanshu chauhan\\anaconda3\\lib\\site-packages (from rich->keras-core->keras-tuner) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\priyanshu chauhan\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras-core->keras-tuner) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U keras-tuner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90faba03",
   "metadata": {},
   "source": [
    "# Tuning the ANN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "232d00c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    }
   ],
   "source": [
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4e92d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizer_selection(hp):\n",
    "    #initialize the model\n",
    "    model = Sequential()\n",
    "    #Add hidden layer\n",
    "    model.add(Dense(units=10, activation='relu'))\n",
    "    #Add output layer\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "    #Optimizer selection\n",
    "    optim = hp.Choice('optimizer', values = ['sgd','adam','rmsprop'])\n",
    "    model.compile(optimizer=optim, loss = 'binary_crossentropy', metrics = 'accuracy')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "22f87f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from .\\untitled_project\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.RandomSearch(\n",
    "    optimizer_selection,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "119fd9b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tuner.search(xtrain,ytrain, epochs = 3, validation_data = (xtest,ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32e8f15e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'optimizer': 'adam'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner.get_best_hyperparameters()[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "095a71bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 2s 5ms/step - loss: 0.4374 - accuracy: 0.8169 - val_loss: 0.4284 - val_accuracy: 0.8170\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4229 - accuracy: 0.8195 - val_loss: 0.4156 - val_accuracy: 0.8240\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.4131 - accuracy: 0.8239 - val_loss: 0.4065 - val_accuracy: 0.8310\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.4038 - accuracy: 0.8288 - val_loss: 0.3981 - val_accuracy: 0.8345\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3948 - accuracy: 0.8331 - val_loss: 0.3898 - val_accuracy: 0.8400\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3865 - accuracy: 0.8374 - val_loss: 0.3824 - val_accuracy: 0.8400\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3793 - accuracy: 0.8430 - val_loss: 0.3759 - val_accuracy: 0.8440\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3728 - accuracy: 0.8443 - val_loss: 0.3712 - val_accuracy: 0.8415\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3675 - accuracy: 0.8465 - val_loss: 0.3665 - val_accuracy: 0.8465\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3630 - accuracy: 0.8503 - val_loss: 0.3620 - val_accuracy: 0.8495\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3589 - accuracy: 0.8515 - val_loss: 0.3580 - val_accuracy: 0.8470\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3559 - accuracy: 0.8521 - val_loss: 0.3543 - val_accuracy: 0.8515\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3529 - accuracy: 0.8533 - val_loss: 0.3516 - val_accuracy: 0.8520\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3508 - accuracy: 0.8554 - val_loss: 0.3490 - val_accuracy: 0.8545\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3490 - accuracy: 0.8559 - val_loss: 0.3481 - val_accuracy: 0.8560\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3477 - accuracy: 0.8576 - val_loss: 0.3458 - val_accuracy: 0.8580\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3461 - accuracy: 0.8568 - val_loss: 0.3441 - val_accuracy: 0.8590\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3453 - accuracy: 0.8576 - val_loss: 0.3431 - val_accuracy: 0.8600\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3444 - accuracy: 0.8581 - val_loss: 0.3430 - val_accuracy: 0.8600\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3438 - accuracy: 0.8587 - val_loss: 0.3410 - val_accuracy: 0.8610\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3431 - accuracy: 0.8599 - val_loss: 0.3417 - val_accuracy: 0.8600\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3425 - accuracy: 0.8605 - val_loss: 0.3403 - val_accuracy: 0.8585\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3423 - accuracy: 0.8605 - val_loss: 0.3399 - val_accuracy: 0.8615\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3417 - accuracy: 0.8602 - val_loss: 0.3391 - val_accuracy: 0.8605\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3412 - accuracy: 0.8589 - val_loss: 0.3397 - val_accuracy: 0.8590\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3408 - accuracy: 0.8595 - val_loss: 0.3380 - val_accuracy: 0.8655\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3406 - accuracy: 0.8599 - val_loss: 0.3385 - val_accuracy: 0.8605\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3400 - accuracy: 0.8611 - val_loss: 0.3374 - val_accuracy: 0.8635\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3399 - accuracy: 0.8622 - val_loss: 0.3374 - val_accuracy: 0.8620\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3396 - accuracy: 0.8608 - val_loss: 0.3368 - val_accuracy: 0.8620\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3396 - accuracy: 0.8609 - val_loss: 0.3376 - val_accuracy: 0.8630\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3392 - accuracy: 0.8610 - val_loss: 0.3375 - val_accuracy: 0.8605\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3393 - accuracy: 0.8618 - val_loss: 0.3382 - val_accuracy: 0.8595\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3387 - accuracy: 0.8614 - val_loss: 0.3382 - val_accuracy: 0.8640\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3383 - accuracy: 0.8609 - val_loss: 0.3375 - val_accuracy: 0.8575\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3386 - accuracy: 0.8611 - val_loss: 0.3377 - val_accuracy: 0.8630\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3380 - accuracy: 0.8610 - val_loss: 0.3396 - val_accuracy: 0.8615\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3382 - accuracy: 0.8624 - val_loss: 0.3372 - val_accuracy: 0.8610\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3381 - accuracy: 0.8616 - val_loss: 0.3369 - val_accuracy: 0.8620\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3377 - accuracy: 0.8625 - val_loss: 0.3372 - val_accuracy: 0.8625\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3375 - accuracy: 0.8622 - val_loss: 0.3369 - val_accuracy: 0.8615\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3371 - accuracy: 0.8626 - val_loss: 0.3373 - val_accuracy: 0.8620\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3374 - accuracy: 0.8612 - val_loss: 0.3362 - val_accuracy: 0.8630\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3374 - accuracy: 0.8609 - val_loss: 0.3372 - val_accuracy: 0.8625\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3372 - accuracy: 0.8616 - val_loss: 0.3366 - val_accuracy: 0.8620\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3369 - accuracy: 0.8630 - val_loss: 0.3373 - val_accuracy: 0.8585\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3369 - accuracy: 0.8629 - val_loss: 0.3361 - val_accuracy: 0.8625\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3368 - accuracy: 0.8616 - val_loss: 0.3362 - val_accuracy: 0.8615\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3365 - accuracy: 0.8630 - val_loss: 0.3358 - val_accuracy: 0.8615\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3365 - accuracy: 0.8635 - val_loss: 0.3361 - val_accuracy: 0.8630\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3366 - accuracy: 0.8622 - val_loss: 0.3365 - val_accuracy: 0.8620\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3362 - accuracy: 0.8616 - val_loss: 0.3371 - val_accuracy: 0.8635\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3363 - accuracy: 0.8624 - val_loss: 0.3374 - val_accuracy: 0.8625\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3358 - accuracy: 0.8611 - val_loss: 0.3365 - val_accuracy: 0.8625\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3359 - accuracy: 0.8620 - val_loss: 0.3366 - val_accuracy: 0.8630\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3359 - accuracy: 0.8611 - val_loss: 0.3366 - val_accuracy: 0.8620\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3356 - accuracy: 0.8624 - val_loss: 0.3372 - val_accuracy: 0.8615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3358 - accuracy: 0.8614 - val_loss: 0.3369 - val_accuracy: 0.8620\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3353 - accuracy: 0.8620 - val_loss: 0.3355 - val_accuracy: 0.8625\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3352 - accuracy: 0.8615 - val_loss: 0.3359 - val_accuracy: 0.8650\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3351 - accuracy: 0.8614 - val_loss: 0.3361 - val_accuracy: 0.8645\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3354 - accuracy: 0.8619 - val_loss: 0.3379 - val_accuracy: 0.8600\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3351 - accuracy: 0.8624 - val_loss: 0.3371 - val_accuracy: 0.8620\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3350 - accuracy: 0.8615 - val_loss: 0.3372 - val_accuracy: 0.8620\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3347 - accuracy: 0.8608 - val_loss: 0.3379 - val_accuracy: 0.8610\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3348 - accuracy: 0.8618 - val_loss: 0.3368 - val_accuracy: 0.8625\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3346 - accuracy: 0.8629 - val_loss: 0.3364 - val_accuracy: 0.8645\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3347 - accuracy: 0.8612 - val_loss: 0.3375 - val_accuracy: 0.8615\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3348 - accuracy: 0.8624 - val_loss: 0.3370 - val_accuracy: 0.8630\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3348 - accuracy: 0.8615 - val_loss: 0.3373 - val_accuracy: 0.8605\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3347 - accuracy: 0.8629 - val_loss: 0.3370 - val_accuracy: 0.8625\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3344 - accuracy: 0.8627 - val_loss: 0.3369 - val_accuracy: 0.8625\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3345 - accuracy: 0.8618 - val_loss: 0.3367 - val_accuracy: 0.8615\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3342 - accuracy: 0.8616 - val_loss: 0.3368 - val_accuracy: 0.8620\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3343 - accuracy: 0.8624 - val_loss: 0.3360 - val_accuracy: 0.8640\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3341 - accuracy: 0.8614 - val_loss: 0.3356 - val_accuracy: 0.8625\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3342 - accuracy: 0.8631 - val_loss: 0.3366 - val_accuracy: 0.8620\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3340 - accuracy: 0.8634 - val_loss: 0.3363 - val_accuracy: 0.8610\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3343 - accuracy: 0.8619 - val_loss: 0.3353 - val_accuracy: 0.8640\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3341 - accuracy: 0.8610 - val_loss: 0.3363 - val_accuracy: 0.8620\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3339 - accuracy: 0.8624 - val_loss: 0.3357 - val_accuracy: 0.8615\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3337 - accuracy: 0.8626 - val_loss: 0.3371 - val_accuracy: 0.8640\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3337 - accuracy: 0.8615 - val_loss: 0.3357 - val_accuracy: 0.8615\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3338 - accuracy: 0.8621 - val_loss: 0.3345 - val_accuracy: 0.8605\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3338 - accuracy: 0.8619 - val_loss: 0.3363 - val_accuracy: 0.8610\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3334 - accuracy: 0.8621 - val_loss: 0.3359 - val_accuracy: 0.8615\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3335 - accuracy: 0.8622 - val_loss: 0.3359 - val_accuracy: 0.8605\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3330 - accuracy: 0.8633 - val_loss: 0.3377 - val_accuracy: 0.8650\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3335 - accuracy: 0.8624 - val_loss: 0.3361 - val_accuracy: 0.8630\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3334 - accuracy: 0.8639 - val_loss: 0.3353 - val_accuracy: 0.8615\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3338 - accuracy: 0.8641 - val_loss: 0.3357 - val_accuracy: 0.8600\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3332 - accuracy: 0.8620 - val_loss: 0.3353 - val_accuracy: 0.8610\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3333 - accuracy: 0.8626 - val_loss: 0.3356 - val_accuracy: 0.8645\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3333 - accuracy: 0.8627 - val_loss: 0.3358 - val_accuracy: 0.8635\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3331 - accuracy: 0.8631 - val_loss: 0.3380 - val_accuracy: 0.8615\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3328 - accuracy: 0.8622 - val_loss: 0.3356 - val_accuracy: 0.8615\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3327 - accuracy: 0.8620 - val_loss: 0.3357 - val_accuracy: 0.8605\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3328 - accuracy: 0.8629 - val_loss: 0.3358 - val_accuracy: 0.8625\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3329 - accuracy: 0.8610 - val_loss: 0.3358 - val_accuracy: 0.8620\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3328 - accuracy: 0.8614 - val_loss: 0.3349 - val_accuracy: 0.8610\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1c4a71eabd0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tuner.get_best_models(num_models=1)[0]\n",
    "model.fit(xtrain,ytrain, epochs = 100, validation_data = (xtest,ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274bf828",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8557cfe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>461.527929</td>\n",
       "      <td>999.787558</td>\n",
       "      <td>999.766096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>548.130012</td>\n",
       "      <td>998.861615</td>\n",
       "      <td>1001.042403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>410.297162</td>\n",
       "      <td>1000.070267</td>\n",
       "      <td>998.844015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>540.382220</td>\n",
       "      <td>999.952251</td>\n",
       "      <td>1000.440940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>546.024553</td>\n",
       "      <td>1000.446011</td>\n",
       "      <td>1000.338531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>476.526078</td>\n",
       "      <td>1000.018988</td>\n",
       "      <td>999.672732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>457.313186</td>\n",
       "      <td>998.855379</td>\n",
       "      <td>1000.020026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>456.720993</td>\n",
       "      <td>1001.451646</td>\n",
       "      <td>998.847605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>403.315576</td>\n",
       "      <td>1000.771023</td>\n",
       "      <td>998.562851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>599.367094</td>\n",
       "      <td>999.232244</td>\n",
       "      <td>1001.451407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          price     feature1     feature2\n",
       "0    461.527929   999.787558   999.766096\n",
       "1    548.130012   998.861615  1001.042403\n",
       "2    410.297162  1000.070267   998.844015\n",
       "3    540.382220   999.952251  1000.440940\n",
       "4    546.024553  1000.446011  1000.338531\n",
       "..          ...          ...          ...\n",
       "995  476.526078  1000.018988   999.672732\n",
       "996  457.313186   998.855379  1000.020026\n",
       "997  456.720993  1001.451646   998.847605\n",
       "998  403.315576  1000.771023   998.562851\n",
       "999  599.367094   999.232244  1001.451407\n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"D:\\\\Datasets-main\\\\Regression.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "90bf847f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.iloc[:,1:]\n",
    "y = df['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1b7b96a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.23277509, -0.22551031],\n",
       "       [-1.18389307,  1.12100979],\n",
       "       [ 0.05762098, -1.19831827],\n",
       "       ...,\n",
       "       [ 1.47655818, -1.19452982],\n",
       "       [ 0.77742978, -1.49494959],\n",
       "       [-0.80318737,  1.55251428]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = sc.fit_transform(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8847ebe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain,xtest,ytrain,ytest = train_test_split(x,y,test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c228276b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "25/25 [==============================] - 1s 17ms/step - loss: 255705.5156 - val_loss: 262407.5312\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 255096.9844 - val_loss: 261738.7656\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 254285.2031 - val_loss: 260784.7969\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 253118.0938 - val_loss: 259396.6562\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 251439.5938 - val_loss: 257390.2344\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 249003.0781 - val_loss: 254524.3594\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 245595.0625 - val_loss: 250602.6875\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 241041.2969 - val_loss: 245467.9375\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 235180.6875 - val_loss: 238932.5469\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 227840.7812 - val_loss: 230753.6250\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 218792.7031 - val_loss: 220849.4062\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 208056.0938 - val_loss: 209212.2031\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 195638.2031 - val_loss: 196003.2812\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 181781.8750 - val_loss: 181300.1562\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 166505.1094 - val_loss: 165620.4688\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 150418.7344 - val_loss: 148897.0625\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 133683.0781 - val_loss: 131692.9531\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 116748.5391 - val_loss: 114488.6797\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 100042.1094 - val_loss: 97776.2578\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 84157.3203 - val_loss: 81758.6328\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 69273.4531 - val_loss: 67159.6719\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 55958.0312 - val_loss: 53990.7148\n",
      "Epoch 23/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 44313.2383 - val_loss: 42612.3086\n",
      "Epoch 24/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 34499.6680 - val_loss: 33113.7383\n",
      "Epoch 25/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 26497.4883 - val_loss: 25520.5332\n",
      "Epoch 26/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 20283.2969 - val_loss: 19579.5176\n",
      "Epoch 27/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 15562.4004 - val_loss: 15149.2402\n",
      "Epoch 28/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 12156.2041 - val_loss: 11878.5264\n",
      "Epoch 29/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 9730.9971 - val_loss: 9564.4492\n",
      "Epoch 30/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 8079.2949 - val_loss: 7927.6870\n",
      "Epoch 31/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 6947.6206 - val_loss: 6810.9800\n",
      "Epoch 32/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 6171.3994 - val_loss: 6026.3267\n",
      "Epoch 33/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 5620.8218 - val_loss: 5454.7183\n",
      "Epoch 34/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 5210.4858 - val_loss: 5025.1089\n",
      "Epoch 35/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 4878.8228 - val_loss: 4689.2324\n",
      "Epoch 36/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 4605.7949 - val_loss: 4388.4688\n",
      "Epoch 37/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 4361.9048 - val_loss: 4136.5005\n",
      "Epoch 38/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 4135.0317 - val_loss: 3916.4744\n",
      "Epoch 39/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 3930.6375 - val_loss: 3707.2737\n",
      "Epoch 40/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 3734.8550 - val_loss: 3524.8857\n",
      "Epoch 41/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 3546.3347 - val_loss: 3341.4934\n",
      "Epoch 42/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 3370.0193 - val_loss: 3167.3882\n",
      "Epoch 43/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 3200.5713 - val_loss: 3003.4475\n",
      "Epoch 44/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 3040.0867 - val_loss: 2855.0142\n",
      "Epoch 45/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 2890.6492 - val_loss: 2714.0852\n",
      "Epoch 46/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 2743.1509 - val_loss: 2574.7351\n",
      "Epoch 47/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 2608.0852 - val_loss: 2449.8765\n",
      "Epoch 48/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 2477.5740 - val_loss: 2325.9817\n",
      "Epoch 49/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 2352.3918 - val_loss: 2214.3206\n",
      "Epoch 50/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 2239.9280 - val_loss: 2100.6694\n",
      "Epoch 51/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 2126.4592 - val_loss: 1996.5322\n",
      "Epoch 52/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 2017.7350 - val_loss: 1904.2351\n",
      "Epoch 53/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 1919.7499 - val_loss: 1807.6724\n",
      "Epoch 54/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 1823.6311 - val_loss: 1718.5164\n",
      "Epoch 55/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 1734.7125 - val_loss: 1637.6019\n",
      "Epoch 56/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 1651.2970 - val_loss: 1557.9408\n",
      "Epoch 57/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 1571.2974 - val_loss: 1482.8517\n",
      "Epoch 58/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 1495.7883 - val_loss: 1412.4563\n",
      "Epoch 59/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 1424.0532 - val_loss: 1346.0400\n",
      "Epoch 60/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 1358.7003 - val_loss: 1281.4275\n",
      "Epoch 61/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 1291.0406 - val_loss: 1222.2341\n",
      "Epoch 62/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 1231.2035 - val_loss: 1166.6494\n",
      "Epoch 63/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 1172.7286 - val_loss: 1109.4351\n",
      "Epoch 64/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 1119.3250 - val_loss: 1060.4907\n",
      "Epoch 65/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 1065.2194 - val_loss: 1006.1671\n",
      "Epoch 66/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 1015.5925 - val_loss: 960.4816\n",
      "Epoch 67/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 969.8370 - val_loss: 921.0610\n",
      "Epoch 68/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 926.7684 - val_loss: 875.5224\n",
      "Epoch 69/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 883.8046 - val_loss: 841.1843\n",
      "Epoch 70/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 846.2807 - val_loss: 799.5316\n",
      "Epoch 71/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 806.0600 - val_loss: 766.1495\n",
      "Epoch 72/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 771.0844 - val_loss: 732.1297\n",
      "Epoch 73/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 738.8759 - val_loss: 698.8398\n",
      "Epoch 74/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 707.2957 - val_loss: 672.3847\n",
      "Epoch 75/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 677.4750 - val_loss: 642.3215\n",
      "Epoch 76/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 648.3712 - val_loss: 617.3629\n",
      "Epoch 77/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 620.9744 - val_loss: 593.3231\n",
      "Epoch 78/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 596.2382 - val_loss: 568.9500\n",
      "Epoch 79/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 572.1363 - val_loss: 546.0382\n",
      "Epoch 80/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 549.0980 - val_loss: 524.3749\n",
      "Epoch 81/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 527.4625 - val_loss: 503.2673\n",
      "Epoch 82/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 505.7137 - val_loss: 484.8916\n",
      "Epoch 83/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 488.0454 - val_loss: 470.3557\n",
      "Epoch 84/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 466.9611 - val_loss: 452.2889\n",
      "Epoch 85/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 450.0237 - val_loss: 436.9682\n",
      "Epoch 86/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 433.2682 - val_loss: 418.6942\n",
      "Epoch 87/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 418.1396 - val_loss: 405.7883\n",
      "Epoch 88/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 400.9751 - val_loss: 391.5162\n",
      "Epoch 89/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 386.4610 - val_loss: 378.1178\n",
      "Epoch 90/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 372.8833 - val_loss: 366.8235\n",
      "Epoch 91/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 360.2766 - val_loss: 354.4840\n",
      "Epoch 92/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 347.1512 - val_loss: 343.5348\n",
      "Epoch 93/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 335.0864 - val_loss: 331.5873\n",
      "Epoch 94/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 323.9610 - val_loss: 323.9326\n",
      "Epoch 95/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 311.8763 - val_loss: 312.7759\n",
      "Epoch 96/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 302.2040 - val_loss: 303.3351\n",
      "Epoch 97/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 291.6833 - val_loss: 295.8204\n",
      "Epoch 98/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 281.8803 - val_loss: 286.3847\n",
      "Epoch 99/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 272.3020 - val_loss: 279.7597\n",
      "Epoch 100/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 264.0735 - val_loss: 270.3049\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1c4a73ea490>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann = Sequential()\n",
    "\n",
    "ann.add(Dense(units=30, activation='relu'))\n",
    "ann.add(Dense(units=20, activation='relu'))\n",
    "\n",
    "ann.add(Dense(units=1))\n",
    "\n",
    "ann.compile(optimizer='adam',loss = 'mse')\n",
    "\n",
    "ann.fit(xtrain,ytrain, epochs = 100, validation_data = (xtest,ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ec44946c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[478.61166],\n",
       "       [524.21155],\n",
       "       [499.36566],\n",
       "       [539.3491 ],\n",
       "       [652.0006 ],\n",
       "       [341.14517],\n",
       "       [365.48685],\n",
       "       [363.2898 ],\n",
       "       [712.8395 ],\n",
       "       [509.37408],\n",
       "       [483.8459 ],\n",
       "       [507.33292],\n",
       "       [499.15567],\n",
       "       [374.00037],\n",
       "       [545.89575],\n",
       "       [493.91235],\n",
       "       [574.77856],\n",
       "       [547.5021 ],\n",
       "       [486.31134],\n",
       "       [499.10602],\n",
       "       [476.07227],\n",
       "       [604.40906],\n",
       "       [443.39212],\n",
       "       [576.7361 ],\n",
       "       [427.10812],\n",
       "       [521.5325 ],\n",
       "       [377.6876 ],\n",
       "       [502.07407],\n",
       "       [540.626  ],\n",
       "       [339.14948],\n",
       "       [446.53635],\n",
       "       [640.0771 ],\n",
       "       [559.90155],\n",
       "       [539.36194],\n",
       "       [603.7174 ],\n",
       "       [554.4552 ],\n",
       "       [417.69473],\n",
       "       [570.16125],\n",
       "       [567.3756 ],\n",
       "       [526.07086],\n",
       "       [420.07584],\n",
       "       [724.17896],\n",
       "       [523.951  ],\n",
       "       [529.5708 ],\n",
       "       [521.8362 ],\n",
       "       [465.66397],\n",
       "       [531.40204],\n",
       "       [526.47473],\n",
       "       [583.67944],\n",
       "       [468.24188],\n",
       "       [389.73495],\n",
       "       [625.1558 ],\n",
       "       [805.49927],\n",
       "       [534.5912 ],\n",
       "       [662.1864 ],\n",
       "       [544.7611 ],\n",
       "       [490.1123 ],\n",
       "       [544.46924],\n",
       "       [546.8735 ],\n",
       "       [356.5761 ],\n",
       "       [641.75635],\n",
       "       [474.10977],\n",
       "       [484.90546],\n",
       "       [505.43558],\n",
       "       [560.0786 ],\n",
       "       [333.80823],\n",
       "       [552.5421 ],\n",
       "       [548.19836],\n",
       "       [444.14096],\n",
       "       [596.7441 ],\n",
       "       [559.16437],\n",
       "       [431.41006],\n",
       "       [461.7706 ],\n",
       "       [666.4713 ],\n",
       "       [391.93753],\n",
       "       [548.2684 ],\n",
       "       [336.88947],\n",
       "       [451.90637],\n",
       "       [600.0377 ],\n",
       "       [537.83307],\n",
       "       [451.1186 ],\n",
       "       [444.28275],\n",
       "       [347.45898],\n",
       "       [471.35666],\n",
       "       [385.06845],\n",
       "       [658.4496 ],\n",
       "       [390.79022],\n",
       "       [556.1543 ],\n",
       "       [566.946  ],\n",
       "       [351.26996],\n",
       "       [400.55942],\n",
       "       [504.41858],\n",
       "       [547.83276],\n",
       "       [560.8881 ],\n",
       "       [731.8708 ],\n",
       "       [537.4524 ],\n",
       "       [614.77704],\n",
       "       [614.10065],\n",
       "       [619.59894],\n",
       "       [539.49164],\n",
       "       [504.03485],\n",
       "       [522.4474 ],\n",
       "       [579.2395 ],\n",
       "       [436.8146 ],\n",
       "       [607.52295],\n",
       "       [423.91174],\n",
       "       [354.3101 ],\n",
       "       [435.09995],\n",
       "       [404.0726 ],\n",
       "       [489.2013 ],\n",
       "       [487.44446],\n",
       "       [397.71964],\n",
       "       [479.31424],\n",
       "       [418.70413],\n",
       "       [325.1947 ],\n",
       "       [590.1451 ],\n",
       "       [495.80563],\n",
       "       [402.36392],\n",
       "       [418.74118],\n",
       "       [564.2296 ],\n",
       "       [478.27084],\n",
       "       [458.44046],\n",
       "       [534.0515 ],\n",
       "       [539.1425 ],\n",
       "       [564.78046],\n",
       "       [502.1531 ],\n",
       "       [512.4316 ],\n",
       "       [391.64676],\n",
       "       [560.9006 ],\n",
       "       [583.9731 ],\n",
       "       [589.2635 ],\n",
       "       [438.49088],\n",
       "       [558.24524],\n",
       "       [388.35696],\n",
       "       [473.57828],\n",
       "       [644.7375 ],\n",
       "       [635.6841 ],\n",
       "       [503.80838],\n",
       "       [605.40454],\n",
       "       [600.55774],\n",
       "       [574.17377],\n",
       "       [464.0505 ],\n",
       "       [666.06464],\n",
       "       [345.76605],\n",
       "       [486.49014],\n",
       "       [538.8317 ],\n",
       "       [527.4497 ],\n",
       "       [575.5781 ],\n",
       "       [641.0327 ],\n",
       "       [496.89432],\n",
       "       [483.76392],\n",
       "       [500.29437],\n",
       "       [344.19046],\n",
       "       [480.2733 ],\n",
       "       [550.02234],\n",
       "       [460.23593],\n",
       "       [596.8259 ],\n",
       "       [567.4081 ],\n",
       "       [457.84042],\n",
       "       [446.55713],\n",
       "       [454.5744 ],\n",
       "       [535.2765 ],\n",
       "       [398.227  ],\n",
       "       [507.52112],\n",
       "       [469.66553],\n",
       "       [341.80762],\n",
       "       [539.56476],\n",
       "       [404.49893],\n",
       "       [619.2831 ],\n",
       "       [664.95197],\n",
       "       [421.67935],\n",
       "       [466.7369 ],\n",
       "       [497.54636],\n",
       "       [460.63034],\n",
       "       [391.3074 ],\n",
       "       [614.37396],\n",
       "       [520.7626 ],\n",
       "       [638.3009 ],\n",
       "       [336.5054 ],\n",
       "       [441.3969 ],\n",
       "       [461.98557],\n",
       "       [328.5557 ],\n",
       "       [368.2539 ],\n",
       "       [549.2743 ],\n",
       "       [505.07837],\n",
       "       [501.10052],\n",
       "       [476.88315],\n",
       "       [508.19916],\n",
       "       [514.35565],\n",
       "       [365.96423],\n",
       "       [438.6024 ],\n",
       "       [515.62305],\n",
       "       [504.2036 ],\n",
       "       [547.86755],\n",
       "       [451.05646],\n",
       "       [454.12646],\n",
       "       [581.10254],\n",
       "       [488.54752],\n",
       "       [508.28873],\n",
       "       [460.07306]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yp = ann.predict(xtest)\n",
    "yp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "91aba886",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c73c5819",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#'history.history' function stores the training loss and test loss in dictionary format.\n",
    "loss = pd.DataFrame(ann.history.history)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ec1cf2c4",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "no numeric data to plot",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m loss\u001b[38;5;241m.\u001b[39mplot()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\plotting\\_core.py:1000\u001b[0m, in \u001b[0;36mPlotAccessor.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    997\u001b[0m             label_name \u001b[38;5;241m=\u001b[39m label_kw \u001b[38;5;129;01mor\u001b[39;00m data\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m    998\u001b[0m             data\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m label_name\n\u001b[1;32m-> 1000\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m plot_backend\u001b[38;5;241m.\u001b[39mplot(data, kind\u001b[38;5;241m=\u001b[39mkind, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\plotting\\_matplotlib\\__init__.py:71\u001b[0m, in \u001b[0;36mplot\u001b[1;34m(data, kind, **kwargs)\u001b[0m\n\u001b[0;32m     69\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124max\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(ax, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft_ax\u001b[39m\u001b[38;5;124m\"\u001b[39m, ax)\n\u001b[0;32m     70\u001b[0m plot_obj \u001b[38;5;241m=\u001b[39m PLOT_CLASSES[kind](data, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 71\u001b[0m plot_obj\u001b[38;5;241m.\u001b[39mgenerate()\n\u001b[0;32m     72\u001b[0m plot_obj\u001b[38;5;241m.\u001b[39mdraw()\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m plot_obj\u001b[38;5;241m.\u001b[39mresult\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\plotting\\_matplotlib\\core.py:450\u001b[0m, in \u001b[0;36mMPLPlot.generate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    449\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_args_adjust()\n\u001b[1;32m--> 450\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_plot_data()\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setup_subplots()\n\u001b[0;32m    452\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_plot()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\plotting\\_matplotlib\\core.py:635\u001b[0m, in \u001b[0;36mMPLPlot._compute_plot_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;66;03m# no non-numeric frames or series allowed\u001b[39;00m\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_empty:\n\u001b[1;32m--> 635\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno numeric data to plot\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    637\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m numeric_data\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_to_ndarray)\n",
      "\u001b[1;31mTypeError\u001b[0m: no numeric data to plot"
     ]
    }
   ],
   "source": [
    "loss.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fbf0e4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5ad442e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9661797394443804"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(ytest,yp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89e92ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
